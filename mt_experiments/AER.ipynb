{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-21 07:23:09 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "#torch.cuda.set_device(3)\n",
    "#torch.cuda.current_device()\n",
    "\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from wrappers.transformer_wrapper import FairseqTransformerHub\n",
    "from wrappers.multilingual_transformer_wrapper import FairseqMultilingualTransformerHub\n",
    "from alignment.aer import aer\n",
    "import itertools\n",
    "\n",
    "import alignment.align as align\n",
    "from types import SimpleNamespace\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "\n",
    "logger.setLevel('WARNING')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'multilingual'# bilingual/multilingual\n",
    "model_size = 'small'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model == 'bilingual':\n",
    "    # Bilingual paths\n",
    "    europarl_dir = Path(os.environ['EUROPARL_DATA_DIR'])\n",
    "    ckpt_dir = Path(os.environ['EUROPARL_CKPT_DIR'])\n",
    "    # Choose model\n",
    "    model_type = 'baseline'\n",
    "    seed = 9819 # 2253  2453  5498  9240  9819\n",
    "    model_name = f\"{model_type}/{seed}\"\n",
    "\n",
    "    args = SimpleNamespace(\n",
    "        src = \"de\",\n",
    "        tgt = \"en\",\n",
    "        tokenizer = \"bpe\",\n",
    "        test_set_dir = Path(os.environ['EUROPARL_DATA_DIR']) / \"processed_data/\",\n",
    "        model_name_save = model_name.replace('/','_'),\n",
    "        pre_layer_norm = False,\n",
    "        num_layers = 6\n",
    "        )\n",
    "\n",
    "elif model == 'multilingual':\n",
    "    # Multilingual paths\n",
    "    ckpt_dir = Path(os.environ['M2M_CKPT_DIR'])\n",
    "    europarl_dir = Path(\"./data/de-en\")\n",
    "    model_size = 'big' # small (412M) /big (1.2B)\n",
    "\n",
    "    args = SimpleNamespace(\n",
    "        src = \"de\",\n",
    "        tgt = \"en\",\n",
    "        tokenizer = \"spm\",\n",
    "        test_set_dir = Path(\"./data/de-en\").as_posix(),\n",
    "        model_name_save = f'm2m100_{model_size}',\n",
    "        pre_layer_norm = True,\n",
    "        num_layers = 12\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-21 07:25:07 | WARNING | fairseq.data.multilingual.multilingual_data_manager | External language dictionary is not provided; use lang-pairs to infer the set of supported languages. The language ordering is not stable which might cause misalignment in pretraining and finetuning.\n"
     ]
    }
   ],
   "source": [
    "#ckpt_dir = Path(os.environ['IWSLT14_CKPT_DIR'])\n",
    "\n",
    "lang_flores_dict = {'en': 'eng', 'es': 'spa', 'zu': 'zul',\n",
    "                    'de': 'deu', 'yo': 'yor', 'ms': 'msa',\n",
    "                    'fr': 'fra', 'xh': 'xho'}\n",
    "source_lang = 'de'\n",
    "target_lang = 'en'\n",
    "if model == 'bilingual':\n",
    "    hub = FairseqTransformerHub.from_pretrained(\n",
    "        ckpt_dir / f\"{model_type}/{seed}\",\n",
    "        checkpoint_file=f\"checkpoint_best.pt\",\n",
    "        data_name_or_path=(europarl_dir / \"processed_data/fairseq_preprocessed_data\").as_posix(), # processed data\n",
    "    )\n",
    "\n",
    "elif model == 'multilingual':\n",
    "    # Checkpoint names\n",
    "    if model_size=='big':\n",
    "        checkpoint_file = '1.2B_last_checkpoint.pt'\n",
    "    else:\n",
    "        checkpoint_file = '418M_last_checkpoint.pt'\n",
    "    data_name_or_path='.'\n",
    "    hub = FairseqMultilingualTransformerHub.from_pretrained(\n",
    "        ckpt_dir,\n",
    "        checkpoint_file=checkpoint_file,\n",
    "        data_name_or_path=data_name_or_path,\n",
    "        source_lang= args.src,\n",
    "        target_lang= args.tgt,\n",
    "        lang_pairs =f'{source_lang}-{target_lang}',\n",
    "        fixed_dictionary=f'{ckpt_dir}/model_dict.128k.txt')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute AER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_list = ['alti', 'decoder.encoder_attn', 'alti_enc_cross_attn','attn_w', 'cross_attn_contributions_proj', 'cross_attn_contrib_proj_alti', 'vector_norms_cross']\n",
    "aer_obt = aer(args, mode_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.93 GiB total capacity; 10.57 GiB already allocated; 18.12 MiB free; 11.07 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24225/4179033803.py\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcontrib_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'l1'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0maer_obt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_contribution_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrib_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/transformer-contributions-nmt_v2/alignment/aer.py\u001b[0m in \u001b[0;36mextract_contribution_matrix\u001b[0;34m(self, hub, contrib_type)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             alti_model = hub.get_contribution_rollout(src_tensor, tgt_tensor, contrib_type,\n\u001b[0m\u001b[1;32m     80\u001b[0m                                                         norm_mode='min_sum')\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/transformer-contributions-nmt_v2/wrappers/transformer_wrapper.py\u001b[0m in \u001b[0;36mget_contribution_rollout\u001b[0;34m(self, src_tensor, tgt_tensor, contrib_type, norm_mode, **contrib_kwargs)\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;31m# Compute joint cross + self attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0mself_dec_contributions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_contributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrib_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdec_sa\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m         \u001b[0mcross_contributions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_contributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrib_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdec_ed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m         \u001b[0mself_dec_contributions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself_dec_contributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcross_contributions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m         \u001b[0mjoint_self_cross_contributions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_contributions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself_dec_contributions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/transformer-contributions-nmt_v2/wrappers/transformer_wrapper.py\u001b[0m in \u001b[0;36mget_contributions\u001b[0;34m(self, src_tensor, tgt_tensor, contrib_type, norm_mode)\u001b[0m\n\u001b[1;32m    497\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Please change the normalization mode to sum one'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m                     \u001b[0mcontributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresultant_norms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'.{l}.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcontrib_type\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m't_vectors'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m                     \u001b[0mcontributions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_contrib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresultant_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresultant_norms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/transformer-contributions-nmt_v2/wrappers/transformer_wrapper.py\u001b[0m in \u001b[0;36m__get_contributions_module\u001b[0;34m(self, layer_inputs, layer_outputs, contrib_type, module_name)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcontrib_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l1'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m             \u001b[0mcontributions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpairwise_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformed_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresultant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m             \u001b[0mresultants_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresultant\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/alti_plus/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mpairwise_distance\u001b[0;34m(x1, x2, p, eps, keepdim)\u001b[0m\n\u001b[1;32m   4222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4223\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairwise_distance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4224\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpairwise_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.93 GiB total capacity; 10.57 GiB already allocated; 18.12 MiB free; 11.07 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "contrib_type = 'l1'\n",
    "aer_obt.extract_contribution_matrix(hub, contrib_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['alti', 'decoder.encoder_attn', 'alti_enc_cross_attn', 'attn_w', 'cross_attn_contributions_proj', 'cross_attn_contrib_proj_alti'])\n",
      "alti\n",
      "decoder.encoder_attn\n",
      "alti_enc_cross_attn\n",
      "attn_w\n",
      "cross_attn_contributions_proj\n",
      "cross_attn_contrib_proj_alti\n",
      "alti\n",
      "decoder.encoder_attn\n",
      "alti_enc_cross_attn\n",
      "attn_w\n",
      "cross_attn_contributions_proj\n",
      "cross_attn_contrib_proj_alti\n"
     ]
    }
   ],
   "source": [
    "aer_obt.extract_alignments(final_punc_mark=False, ignore_eos=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWI:\n",
      "\n",
      "Mode: alti\n",
      "[0.5973234794766803, 0.4379306901028662, 0.4624488165384999, 0.5834415260161789, 0.6851093578348147, 0.700838909417757]\n",
      "\n",
      "Mode: decoder.encoder_attn\n",
      "[0.47103765105363027, 0.2622590632178169, 0.3613802057325477, 0.8368121442125237, 0.830720063916908, 0.8438030560271647]\n",
      "\n",
      "Mode: alti_enc_cross_attn\n",
      "[0.5973234794766803, 0.41980425446919, 0.4998002596624388, 0.8016578448017577, 0.8072505742534705, 0.8353140916808149]\n",
      "\n",
      "Mode: attn_w\n",
      "[0.4966543493458504, 0.2459802257065814, 0.40002996105063415, 0.8208828522920204, 0.8297712973134925, 0.8507939678418057]\n",
      "\n",
      "Mode: cross_attn_contributions_proj\n",
      "[0.6370218715669629, 0.4268950364526116, 0.6398681713772096, 0.8267252571656847, 0.889243982822331, 0.8449515629681414]\n",
      "\n",
      "Mode: cross_attn_contrib_proj_alti\n",
      "[0.7283032058324179, 0.5296115050434436, 0.6806651353240787, 0.8244781783681214, 0.843353640267652, 0.8578348147408369]\n",
      "\n",
      "AWO:\n",
      "\n",
      "Mode: alti\n",
      "[0.7944172575651653, 0.7859782283032059, 0.7295016478577849, 0.6367721961450115, 0.5687106761210426, 0.5575751523020074]\n",
      "\n",
      "Mode: decoder.encoder_attn\n",
      "[0.8521921502047338, 0.8555378008588834, 0.6951962448816538, 0.473035054429242, 0.38919404773794064, 0.5157295515829422]\n",
      "\n",
      "Mode: alti_enc_cross_attn\n",
      "[0.7944172575651653, 0.7869269949066213, 0.6630380505343054, 0.5599720363527414, 0.5099870168780585, 0.5739039248976331]\n",
      "\n",
      "Mode: attn_w\n",
      "[0.8464995505842405, 0.8475481873564367, 0.6474583042045341, 0.4325876360731049, 0.4193548387096774, 0.5595725556776191]\n",
      "\n",
      "Mode: cross_attn_contributions_proj\n",
      "[0.8566363727154699, 0.8137421352242085, 0.47593128932387896, 0.32947168680715067, 0.2643064016778188, 0.37740936782183165]\n",
      "\n",
      "Mode: cross_attn_contrib_proj_alti\n",
      "[0.8419055228203336, 0.7898731648856486, 0.5546289823229802, 0.47103765105363027, 0.41750724058723654, 0.4864176570458404]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mode_list = ['alti', 'decoder.encoder_attn', 'alti_enc_cross_attn', 'attn_w','cross_attn_contributions_proj', 'cross_attn_contrib_proj_alti', 'vector_norms_cross']\n",
    "\n",
    "for setting in ['AWI', 'AWO']:\n",
    "    print(f'{setting}:\\n')\n",
    "    results = aer_obt.calculate_aer(setting)\n",
    "    for mode in mode_list:\n",
    "        print('Mode:', mode)\n",
    "        print(results[mode]['aer'])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "c995e4df3e15fb19e51937be7fa850c4ca509847aa0198273373bdf21279d10e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
